{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"(42000, 785)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0       0       0       0       0       0       0       0       0       0   \n1       0       0       0       0       0       0       0       0       0   \n2       0       0       0       0       0       0       0       0       0   \n3       0       0       0       0       0       0       0       0       0   \n4       0       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 784 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 784 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape\nnum_pixels = test.shape[1]\nnum_pixels","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"784"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.models import Sequential\nfrom keras.datasets import mnist\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\nimport random","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['label'])","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f17fd6952d0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = train.drop(['label'],axis = 1)\nx_test = test\nx_train.head()\n        \n  ","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0       0       0       0       0       0       0       0       0       0   \n1       0       0       0       0       0       0       0       0       0   \n2       0       0       0       0       0       0       0       0       0   \n3       0       0       0       0       0       0       0       0       0   \n4       0       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 784 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 784 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(x_train)\nprint(x_train.shape)\nprint(x_test.shape)\n#already flattened","execution_count":14,"outputs":[{"output_type":"stream","text":"(42000, 784)\n(28000, 784)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets visualize the 1st image\ntemp = np.array(x_train) # transformin datafraem to np array\ntemp = temp[0]   # taking the 1st image\ntemp = temp.reshape(28,28)   # reshaping the flattened image to 28*28 pixels\ntemp\nplt.imshow(temp)","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f17b697c9d0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize inputs from 0-255 to 0-1\nx_train = x_train / 255\nx_test = x_test / 255\ntype(x_train)","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"pandas.core.frame.DataFrame"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train['label']\ny_train = np.array(y_train)\ny_train","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"array([1, 0, 1, ..., 7, 6, 9])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = np.array(x_train)\nx_train","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\ny_train  = to_categorical(y_train)\ny_train","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"array([[0., 1., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train.shape)","execution_count":20,"outputs":[{"output_type":"stream","text":"(42000, 10)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = y_train.shape[1]\nnum_classes","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"10"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#  Build a Conventional Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest = train_test_split(x_train,y_train,test_size = 0.33,random_state = 42)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def classification_model():\n    model = Sequential()\n    model.add(Dense(100, activation='relu', input_dim=num_pixels))\n    model.add(Dense(100, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n    ","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = classification_model()\n\n# fit the model\nmodel.fit(xtrain, ytrain,validation_data = (xtest,ytest), epochs=10, verbose=2)","execution_count":72,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n880/880 - 2s - loss: 0.3267 - accuracy: 0.9065 - val_loss: 0.1683 - val_accuracy: 0.9503\nEpoch 2/10\n880/880 - 2s - loss: 0.1362 - accuracy: 0.9589 - val_loss: 0.1523 - val_accuracy: 0.9526\nEpoch 3/10\n880/880 - 2s - loss: 0.0918 - accuracy: 0.9723 - val_loss: 0.1223 - val_accuracy: 0.9641\nEpoch 4/10\n880/880 - 2s - loss: 0.0675 - accuracy: 0.9795 - val_loss: 0.1192 - val_accuracy: 0.9651\nEpoch 5/10\n880/880 - 2s - loss: 0.0522 - accuracy: 0.9834 - val_loss: 0.1057 - val_accuracy: 0.9692\nEpoch 6/10\n880/880 - 2s - loss: 0.0414 - accuracy: 0.9860 - val_loss: 0.1184 - val_accuracy: 0.9680\nEpoch 7/10\n880/880 - 2s - loss: 0.0313 - accuracy: 0.9902 - val_loss: 0.1264 - val_accuracy: 0.9677\nEpoch 8/10\n880/880 - 2s - loss: 0.0303 - accuracy: 0.9902 - val_loss: 0.1137 - val_accuracy: 0.9683\nEpoch 9/10\n880/880 - 2s - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.1229 - val_accuracy: 0.9685\nEpoch 10/10\n880/880 - 2s - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.1481 - val_accuracy: 0.9644\n","name":"stdout"},{"output_type":"execute_result","execution_count":72,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f176ffa2f10>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Validation Accuracy upto 96.5% \nCan we increase the accuracy more?\n-> CNN "},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(xtest)\n#from sklearn.metrics import confusion_matrix\n#confusion_matrix(ytest,y_pred)\ny_pred","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"array([[2.3686968e-07, 4.2489074e-07, 3.8228100e-06, ..., 3.3037361e-07,\n        9.9999297e-01, 2.0217774e-06],\n       [1.1944411e-08, 9.9565828e-01, 1.4243733e-05, ..., 3.8798784e-03,\n        2.7806917e-04, 2.7292015e-07],\n       [2.9265347e-11, 8.3589221e-12, 7.7471709e-15, ..., 2.3623170e-07,\n        4.4744611e-06, 9.9999487e-01],\n       ...,\n       [1.9729256e-08, 7.5721069e-15, 1.0135074e-10, ..., 4.2182942e-14,\n        1.0944158e-09, 7.0639297e-12],\n       [1.1017929e-11, 9.4023432e-07, 2.1478718e-07, ..., 6.9170494e-07,\n        9.9195427e-07, 1.1445058e-04],\n       [1.2092723e-13, 1.0368773e-10, 1.0000000e+00, ..., 3.3172652e-11,\n        8.0434041e-11, 5.5938077e-16]], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytest","execution_count":56,"outputs":[{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"array([[0., 0., 0., ..., 0., 1., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.argmax(y_pred, axis=1)\ny_pred","execution_count":57,"outputs":[{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"array([8, 1, 9, ..., 6, 3, 2])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub = pd.read_csv(\"/kaggle/input/digit-recognizer/sample_submission.csv\")\nsample_sub","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"       ImageId  Label\n0            1      0\n1            2      0\n2            3      0\n3            4      0\n4            5      0\n...        ...    ...\n27995    27996      0\n27996    27997      0\n27997    27998      0\n27998    27999      0\n27999    28000      0\n\n[28000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27995</th>\n      <td>27996</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27996</th>\n      <td>27997</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27997</th>\n      <td>27998</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27998</th>\n      <td>27999</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27999</th>\n      <td>28000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>28000 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred.shape","execution_count":59,"outputs":[{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"(13860,)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'ImageId':range(1,y_pred.shape[0]+1),'Label':y_pred})\nsubmission","execution_count":60,"outputs":[{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"       ImageId  Label\n0            1      8\n1            2      1\n2            3      9\n3            4      9\n4            5      8\n...        ...    ...\n13855    13856      3\n13856    13857      9\n13857    13858      6\n13858    13859      3\n13859    13860      2\n\n[13860 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13855</th>\n      <td>13856</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>13856</th>\n      <td>13857</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>13857</th>\n      <td>13858</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>13858</th>\n      <td>13859</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>13859</th>\n      <td>13860</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>13860 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir(r'../working')\nsubmission.to_csv(r'submission.csv',index = False)\nfrom IPython.display import FileLink\nFileLink(r'submission.csv')","execution_count":61,"outputs":[{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"/kaggle/working/submission.csv","text/html":"<a href='submission.csv' target='_blank'>submission.csv</a><br>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Basic CNN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train)\nprint(y_train)\nprint(x_train.shape)\nprint(y_train.shape)","execution_count":63,"outputs":[{"output_type":"stream","text":"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n[[0. 1. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]\n [0. 1. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 1. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 1.]]\n(42000, 784)\n(42000, 10)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_test.shape)","execution_count":64,"outputs":[{"output_type":"stream","text":"(28000, 784)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = np.array(x_test)\nx_test","execution_count":65,"outputs":[{"output_type":"execute_result","execution_count":65,"data":{"text/plain":"array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nX_test = x_test.reshape(x_test.shape[0], 28, 28, 1)","execution_count":73,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train  = y_train","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain,xtest,ytrain,ytest = train_test_split(X_train,Y_train,test_size = 0.33,random_state = 42)","execution_count":77,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras.backend.clear_session()\ndef CNN_classification():\n    model = Sequential()\n    # add the first convolution layer\n    model.add(layers.Convolution2D(filters = 16, kernel_size = (3,3), activation = 'relu', input_shape = (28, 28, 1)))\n    # add the first pooling layer\n    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n    # add regularization\n    model.add(layers.Dropout(0.3))\n    # add the second convolution layer\n    model.add(layers.Convolution2D(filters = 16, kernel_size = (3,3), activation = 'relu'))\n    # add the second pooling layer\n    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n    # add regularization\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Flatten())\n    # add the first fully-connected-layer\n    model.add(layers.Dense(units = 128, activation = 'relu'))\n    # add the second fully-connected-layer\n    model.add(layers.Dense(units = 128, activation = 'relu'))\n    # add the output layer \n    model.add(layers.Dense(units = 10, activation = 'softmax'))\n    # compile the model\n    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n    return model\n","execution_count":75,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model = CNN_classification()\nearlystop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n","execution_count":76,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model.fit(xtrain,ytrain,validation_data = (xtest,ytest),epochs = 10,batch_size = 64,callbacks = [earlystop])","execution_count":78,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n440/440 [==============================] - 10s 22ms/step - loss: 0.5216 - accuracy: 0.8296 - val_loss: 0.1435 - val_accuracy: 0.9566\nEpoch 2/10\n440/440 [==============================] - 9s 21ms/step - loss: 0.1733 - accuracy: 0.9448 - val_loss: 0.1131 - val_accuracy: 0.9641\nEpoch 3/10\n440/440 [==============================] - 9s 20ms/step - loss: 0.1303 - accuracy: 0.9580 - val_loss: 0.0723 - val_accuracy: 0.9779\nEpoch 4/10\n440/440 [==============================] - 9s 20ms/step - loss: 0.1078 - accuracy: 0.9655 - val_loss: 0.0768 - val_accuracy: 0.9742\nEpoch 5/10\n440/440 [==============================] - 9s 21ms/step - loss: 0.0932 - accuracy: 0.9708 - val_loss: 0.0548 - val_accuracy: 0.9833\nEpoch 6/10\n440/440 [==============================] - 9s 20ms/step - loss: 0.0854 - accuracy: 0.9726 - val_loss: 0.0509 - val_accuracy: 0.9843\nEpoch 7/10\n440/440 [==============================] - 9s 21ms/step - loss: 0.0755 - accuracy: 0.9761 - val_loss: 0.0487 - val_accuracy: 0.9847\nEpoch 8/10\n440/440 [==============================] - 9s 21ms/step - loss: 0.0705 - accuracy: 0.9776 - val_loss: 0.0448 - val_accuracy: 0.9864\nEpoch 9/10\n440/440 [==============================] - 9s 21ms/step - loss: 0.0672 - accuracy: 0.9775 - val_loss: 0.0461 - val_accuracy: 0.9857\nEpoch 10/10\n440/440 [==============================] - 9s 20ms/step - loss: 0.0606 - accuracy: 0.9798 - val_loss: 0.0423 - val_accuracy: 0.9864\n","name":"stdout"},{"output_type":"execute_result","execution_count":78,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f176eeb7990>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Boom!! Accuracy increases to 98.64% with CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = cnn_model.predict(X_test)\ny_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = np.argmax(y_test,axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_submission = pd.DataFrame({'ImageId':range(1,Y_pred.shape[0]+1),'Label':Y_pred})\ncnn_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir(r'../working')\ncnn_submission.to_csv(r'cnn_submission.csv',index = False)\nfrom IPython.display import FileLink\nFileLink(r'cnn_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Train Test Split in the training data only!!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\n\nX_tr, X_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tr = X_tr.reshape(X_tr.shape[0], 28, 28, 1)\nX_val = X_val.reshape(X_val.shape[0], 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_model = CNN_classification()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_tr.shape)\nprint(y_tr.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define early stopping\nearlystop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n\n# fit the model and save the information in history\nhistory = new_model.fit(\n    X_tr,\n    y_tr,\n    batch_size = 64,\n    epochs = 3,\n    validation_data = (X_val, y_val),\n    callbacks = [earlystop])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_val.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = new_model.evaluate(X_val, y_val, batch_size=64)\nprint(f\"valid loss: {results[0]}, valid acc: {round(results[1]*100,2)}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get probabilities\nprobabilities = new_model.predict(X_val)\n\n# get the prediction class\ny_pred = np.argmax(probabilities, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pick random data\nidx = np.random.randint(0, X_val.shape[0], 32)\n\nfig, ax = plt.subplots(4, 8, figsize=(18,12))\nk = 0\nfor i in range(4):\n    for j in range(8):\n        x = X_val[idx[k]]\n        y = np.argmax(y_val[idx[k]])\n        ypred = y_pred[idx[k]]\n        ax[i,j].imshow(x.reshape(28,28), cmap = plt.cm.binary)\n        ax[i,j].set_title(f'pred:{ypred} ---- truth:{y}')\n        k += 1    \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}